{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ebd3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasketch in /Users/sanjaynithin.sureshkumar/.pyenv/versions/3.12.11/lib/python3.12/site-packages (1.7.0)\n",
      "\u001b[31mERROR: Ignored the following yanked versions: 20081119\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement hashlib (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for hashlib\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasketch hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d56de8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet-Only Hash Functions (Length Preserved)\n",
      "====================================================================================================\n",
      "Name         Length   Hash-V1      Hash-V2      Hash-V3      Hash-V4     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Rajesh       6        qmdohh       mufult       yvsbbo       rojuzm      \n",
      "Rajeev       6        qmdogd       mufuat       yvsblp       rojuab      \n",
      "Suresh       6        lmsohh       nujult       hzzabo       zoruzm      \n",
      "Mahesh       6        mmtohh       guxult       utgibo       nojuzm      \n",
      "Priya        5        lqzxv        kxaca        dprza        plije       \n",
      "Priyanka     8        lqzxvoeu     kxacamse     dprzprsi     plijencu    \n",
      "Arun         4        kqxx         ixez         zdvo         ilun        \n",
      "Arjun        5        kqdkt        ixfog        zhjqb        iljam       \n",
      "Varun        5        amskt        rujog        iqhob        poram       \n",
      "Anjali       6        kcdwss       infota       byzcie       injara      \n",
      "Anjalika     8        kcdwsseu     infotase     byzcioai     injaracu    \n",
      "Deepak       6        xeupvx       viokaq       znfvdq       diopeg      \n",
      "Deepa        5        xeupv        vioka        znfvy        diope       \n",
      "Sanjay       6        lmoxvj       nutgaq       apwrqg       zomyej      \n",
      "Sanjeev      7        lmoxgdp      nutgaek      apwngwa      zomyaep     \n",
      "Amit         4        kezb         ilad         etpl         imit        \n",
      "Amita        5        kezbv        ilada        etprv        imite       \n",
      "Sujesh       6        lmdohh       nufult       hftbbo       zojuzm      \n",
      "Sujeesh      7        lmdogig      nufuaxs      hftbnmw      zojuasn     \n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "# Dataset: Indian first names\n",
    "indian_names = [\n",
    "    \"Rajesh\", \"Rajeev\", \"Suresh\", \"Mahesh\", \"Priya\", \"Priyanka\",\n",
    "    \"Arun\", \"Arjun\", \"Varun\", \"Anjali\", \"Anjalika\", \"Deepak\",\n",
    "    \"Deepa\", \"Sanjay\", \"Sanjeev\", \"Amit\", \"Amita\", \"Sujesh\", \"Sujeesh\"\n",
    "]\n",
    "\n",
    "def alphabet_hash_v1(text):\n",
    "    text = text.lower()\n",
    "    result = []\n",
    "    \n",
    "    for i, char in enumerate(text):\n",
    "        # Create hash from character and position\n",
    "        hash_input = f\"{char}{i}\".encode()\n",
    "        hash_val = int(hashlib.md5(hash_input).hexdigest(), 16)\n",
    "        # Map to alphabet (a-z)\n",
    "        letter = chr(ord('a') + (hash_val % 26))\n",
    "        result.append(letter)\n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "def alphabet_hash_v2(text):\n",
    "    text = text.lower()\n",
    "    result = []\n",
    "    \n",
    "    # Vowels and consonants mapping\n",
    "    vowels = 'aeiou'\n",
    "    consonants = 'bcdfghjklmnpqrstvwxyz'\n",
    "    \n",
    "    for i, char in enumerate(text):\n",
    "        if char in vowels:\n",
    "            # Map vowels to vowels deterministically\n",
    "            hash_val = (ord(char) * (i + 1)) % len(vowels)\n",
    "            result.append(vowels[hash_val])\n",
    "        elif char.isalpha():\n",
    "            # Map consonants to consonants\n",
    "            hash_val = (ord(char) * (i + 1)) % len(consonants)\n",
    "            result.append(consonants[hash_val])\n",
    "        else:\n",
    "            # Spaces or special chars -> 'x'\n",
    "            result.append('x')\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "def alphabet_hash_v3(text):\n",
    "    \"\"\"\n",
    "    Position-aware alphabet hash with semantic preservation\n",
    "    Uses MD5 but outputs only letters\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    result = []\n",
    "    \n",
    "    for i, char in enumerate(text):\n",
    "        # Combine character with its neighbors for context\n",
    "        context = text[max(0, i-1):min(len(text), i+2)]\n",
    "        hash_input = f\"{context}{i}\".encode()\n",
    "        hash_val = int(hashlib.md5(hash_input).hexdigest()[:4], 16)\n",
    "        \n",
    "        # Map to alphabet\n",
    "        letter = chr(ord('a') + (hash_val % 26))\n",
    "        result.append(letter)\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "def alphabet_hash_v4(text):\n",
    "    \"\"\"\n",
    "    Phonetic-aware alphabet hash\n",
    "    Preserves some phonetic properties\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    result = []\n",
    "    \n",
    "    # Phonetic groups\n",
    "    phonetic_map = {\n",
    "        'a': 'aeiou', 'e': 'aeiou', 'i': 'aeiou', 'o': 'aeiou', 'u': 'aeiou',\n",
    "        'b': 'bpv', 'p': 'bpv', 'v': 'bpv',\n",
    "        'd': 'dt', 't': 'dt',\n",
    "        'k': 'kgc', 'g': 'kgc', 'c': 'kgc',\n",
    "        'r': 'rl', 'l': 'rl',\n",
    "        's': 'sz', 'z': 'sz',\n",
    "        'n': 'mn', 'm': 'mn',\n",
    "        'j': 'jy', 'y': 'jy'\n",
    "    }\n",
    "    \n",
    "    for i, char in enumerate(text):\n",
    "        if char in phonetic_map:\n",
    "            group = phonetic_map[char]\n",
    "            # Deterministic selection within phonetic group\n",
    "            hash_val = (ord(char) + i) % len(group)\n",
    "            result.append(group[hash_val])\n",
    "        elif char.isalpha():\n",
    "            # Default fallback\n",
    "            result.append(chr(ord('a') + ((ord(char) - ord('a') + i) % 26)))\n",
    "        else:\n",
    "            result.append('x')\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "# Test all alphabet hash functions\n",
    "print(\"Alphabet-Only Hash Functions (Length Preserved)\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Name':<12} {'Length':<8} {'Hash-V1':<12} {'Hash-V2':<12} {'Hash-V3':<12} {'Hash-V4':<12}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for name in indian_names:\n",
    "    h1 = alphabet_hash_v1(name)\n",
    "    h2 = alphabet_hash_v2(name)\n",
    "    h3 = alphabet_hash_v3(name)\n",
    "    h4 = alphabet_hash_v4(name)\n",
    "    \n",
    "    print(f\"{name:<12} {len(name):<8} {h1:<12} {h2:<12} {h3:<12} {h4:<12}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34511556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEMANTIC HASHING ALGORITHMS (Stateless)\n",
      "========================================================================================================================\n",
      "Name         SimHash (32-bit)                    RandomProj                          MinHash                            \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Rajesh       01010111110010101100100010000110    00000000000000000000000000000000    11101110001010101100110110100000   \n",
      "Rajeev       01000111010110101100100010011110    00000000000000000000000000000000    11010111010111000110010110110001   \n",
      "Suresh       11011000111001001111110010110110    00000000000000000000000000000000    11000010101110110101100111111100   \n",
      "Mahesh       01010111101001011100111010100000    00000000000000000000000000000000    11100010101110100001111010101000   \n",
      "Priya        00010000001000100001010111000000    00000000000000000000000000000000    00010001111001011101100100110011   \n",
      "Priyanka     01111110011110110101110111101000    00000000000000000000000000000000    01110100011001011101110100110011   \n",
      "Arun         10110010010000010110111010000010    00000000000000000000000000000000    11011011110111001010100011001000   \n",
      "Arjun        11000000000000010010111000000100    00000000000000000000000000000000    11001011111111001111101101000001   \n",
      "Varun        10110000010000010110100000000010    00000000000000000000000000000000    11111011110111001011100011000000   \n",
      "Anjali       01001111010111100010011111100000    00000000000000000000000000000000    01110000001000011010110101110111   \n",
      "Anjalika     01011111110111000011010100101000    00000000000000000000000000000000    01110000001001011001110100010111   \n",
      "Deepak       00010101001000101011111001011110    00000000000000000000000000000000    00011010011011100101010100110010   \n",
      "Deepa        00010001000000100000110001011100    00000000000000000000000000000000    00011110011011100101010100110010   \n",
      "Sanjay       11000101100111100010111010101100    00000000000000000000000000000000    01111000011110010000010110011111   \n",
      "Sanjeev      01001101100010100000100000001100    00000000000000000000000000000000    01110111111111010010010110110101   \n",
      "Amit         00011010101001011111110101111001    00000000000000000000000000000000    10101110101110101111001011010000   \n",
      "Amita        00001010000001011110010001111001    00000000000000000000000000000000    10001110101101101111001111010101   \n",
      "Vikram       00101011001110000110110100110110    00000000000000000000000000000000    11001011101001101010100110010011   \n",
      "Vikas        00111001000010000011000100101010    00000000000000000000000000000000    01110110001001100101100100001011   \n",
      "Rahul        00000001101000000100010000000000    00000000000000000000000000000000    11111110100001100010010100101011   \n",
      "\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import math\n",
    "\n",
    "# Dataset: Indian first names\n",
    "indian_names = [\n",
    "    \"Rajesh\", \"Rajeev\", \"Suresh\", \"Mahesh\", \"Priya\", \"Priyanka\",\n",
    "    \"Arun\", \"Arjun\", \"Varun\", \"Anjali\", \"Anjalika\", \"Deepak\",\n",
    "    \"Deepa\", \"Sanjay\", \"Sanjeev\", \"Amit\", \"Amita\", \"Vikram\",\n",
    "    \"Vikas\", \"Rahul\"\n",
    "]\n",
    "\n",
    "# 1. SimHash - Most common semantic hashing algorithm\n",
    "def simhash(text, hash_bits=32):\n",
    "    \"\"\"\n",
    "    SimHash: Semantic hashing for near-duplicate detection\n",
    "    Similar texts produce similar hash codes (low Hamming distance)\n",
    "    Stateless, deterministic\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    # Create features (character bigrams)\n",
    "    features = [text[i:i+2] for i in range(len(text) - 1)]\n",
    "    \n",
    "    # Initialize vector\n",
    "    v = [0] * hash_bits\n",
    "    \n",
    "    # Weight each feature\n",
    "    for feature in features:\n",
    "        # Hash the feature\n",
    "        h = int(hashlib.md5(feature.encode()).hexdigest(), 16)\n",
    "        \n",
    "        # Update vector based on hash bits\n",
    "        for i in range(hash_bits):\n",
    "            if h & (1 << i):\n",
    "                v[i] += 1\n",
    "            else:\n",
    "                v[i] -= 1\n",
    "    \n",
    "    # Generate fingerprint\n",
    "    fingerprint = 0\n",
    "    for i in range(hash_bits):\n",
    "        if v[i] > 0:\n",
    "            fingerprint |= (1 << i)\n",
    "    \n",
    "    # Return as binary string\n",
    "    return format(fingerprint, f'0{hash_bits}b')\n",
    "\n",
    "\n",
    "# 2. Random Projection Hash (LSH-based)\n",
    "def random_projection_hash(text, num_projections=32, seed=42):\n",
    "    \"\"\"\n",
    "    Random Projection Hash: Projects features onto random hyperplanes\n",
    "    Preserves cosine similarity in Hamming space\n",
    "    Stateless when seed is fixed\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    # Create feature vector from character counts\n",
    "    feature_vec = [text.count(chr(ord('a') + i)) for i in range(26)]\n",
    "    \n",
    "    # Generate hash\n",
    "    hash_bits = []\n",
    "    for i in range(num_projections):\n",
    "        # Deterministic random projection using seed\n",
    "        projection = sum(\n",
    "            feature_vec[j] * hash((seed, i, j)) % 3 - 1\n",
    "            for j in range(len(feature_vec))\n",
    "        )\n",
    "        hash_bits.append('1' if projection > 0 else '0')\n",
    "    \n",
    "    return ''.join(hash_bits)\n",
    "\n",
    "\n",
    "# 3. MinHash-based Semantic Hash\n",
    "def minhash_semantic(text, num_hashes=32):\n",
    "    \"\"\"\n",
    "    MinHash: Estimates Jaccard similarity between sets\n",
    "    Used for semantic similarity via set-based representation\n",
    "    Stateless\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    # Create shingles (character n-grams)\n",
    "    shingles = set(text[i:i+2] for i in range(len(text) - 1))\n",
    "    \n",
    "    hash_values = []\n",
    "    for i in range(num_hashes):\n",
    "        min_hash = float('inf')\n",
    "        for shingle in shingles:\n",
    "            h = int(hashlib.md5(f\"{shingle}{i}\".encode()).hexdigest()[:8], 16)\n",
    "            min_hash = min(min_hash, h)\n",
    "        # Convert to bit\n",
    "        hash_values.append('1' if (min_hash % 2) == 0 else '0')\n",
    "    \n",
    "    return ''.join(hash_values)\n",
    "\n",
    "\n",
    "# 4. Feature Hash (Simple Semantic)\n",
    "def feature_hash(text, hash_bits=32):\n",
    "    \"\"\"\n",
    "    Feature Hashing: Maps text features to binary code\n",
    "    Preserves structural similarity\n",
    "    Stateless\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Extract semantic features\n",
    "    features = {\n",
    "        'length': len(text),\n",
    "        'vowels': sum(text.count(v) for v in 'aeiou'),\n",
    "        'consonants': sum(text.count(c) for c in 'bcdfghjklmnpqrstvwxyz'),\n",
    "        'first_char': ord(text[0]) if text else 0,\n",
    "        'last_char': ord(text[-1]) if text else 0,\n",
    "        'unique_chars': len(set(text)),\n",
    "    }\n",
    "    \n",
    "    # Create hash from features\n",
    "    hash_input = ''.join(str(v) for v in features.values())\n",
    "    h = int(hashlib.md5(hash_input.encode()).hexdigest(), 16)\n",
    "    \n",
    "    return format(h % (2**hash_bits), f'0{hash_bits}b')\n",
    "\n",
    "\n",
    "# 5. Spectral Hash (Simplified)\n",
    "def spectral_hash_simple(text, hash_bits=32):\n",
    "    \"\"\"\n",
    "    Spectral Hash: Uses spectral graph theory principles\n",
    "    Simplified version using character frequency spectrum\n",
    "    Stateless\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Create frequency spectrum\n",
    "    freq = [0] * 26\n",
    "    for char in text:\n",
    "        if 'a' <= char <= 'z':\n",
    "            freq[ord(char) - ord('a')] += 1\n",
    "    \n",
    "    # Apply simple spectral transformation\n",
    "    hash_bits_list = []\n",
    "    for i in range(hash_bits):\n",
    "        # Use different frequency combinations\n",
    "        idx1 = (i * 7) % 26\n",
    "        idx2 = (i * 13) % 26\n",
    "        value = freq[idx1] - freq[idx2]\n",
    "        hash_bits_list.append('1' if value > 0 else '0')\n",
    "    \n",
    "    return ''.join(hash_bits_list)\n",
    "\n",
    "\n",
    "# Compute all hashes\n",
    "print(\"SEMANTIC HASHING ALGORITHMS (Stateless)\")\n",
    "print(\"=\" * 120)\n",
    "print(f\"{'Name':<12} {'SimHash (32-bit)':<35} {'RandomProj':<35} {'MinHash':<35}\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "for name in indian_names:\n",
    "    h1 = simhash(name, 32)\n",
    "    h2 = random_projection_hash(name, 32)\n",
    "    h3 = minhash_semantic(name, 32)\n",
    "    \n",
    "    print(f\"{name:<12} {h1:<35} {h2:<35} {h3:<35}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "761896d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32-BIT HASH OUTPUT FORMATS\n",
      "==========================================================================================\n",
      "Name         Binary (32-bit)                     Hex          Integer     \n",
      "------------------------------------------------------------------------------------------\n",
      "Rajesh       01010111110010101100100010000110    57cac886     1472907398  \n",
      "Rajeev       01000111010110101100100010011110    475ac89e     1197131934  \n",
      "Suresh       11011000111001001111110010110110    d8e4fcb6     3638885558  \n",
      "Mahesh       01010111101001011100111010100000    57a5cea0     1470484128  \n",
      "Priya        00010000001000100001010111000000    102215c0     270669248   \n",
      "Priyanka     01111110011110110101110111101000    7e7b5de8     2122014184  \n",
      "Arun         10110010010000010110111010000010    b2416e82     2990632578  \n",
      "Arjun        11000000000000010010111000000100    c0012e04     3221302788  \n",
      "Varun        10110000010000010110100000000010    b0416802     2957076482  \n",
      "Anjali       01001111010111100010011111100000    4f5e27e0     1331570656  \n",
      "\n",
      "==========================================================================================\n",
      "Rajesh     (binary): 01010111110010101100100010000110\n",
      "Rajeev     (binary): 01000111010110101100100010011110\n",
      "\n",
      "Rajesh     (hex):    57cac886\n",
      "Rajeev     (hex):    475ac89e\n",
      "\n",
      "Hamming Distance: 5 bits out of 32\n",
      "Similarity: 84.4%\n",
      "\n",
      "==========================================================================================\n",
      "\n",
      "RECOMMENDATION:\n",
      "- Use BINARY STRINGS for analysis, visualization, and understanding\n",
      "- Use HEX for compact storage and display\n",
      "- Use INTEGER for mathematical operations and indexing\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "indian_names = [\n",
    "    \"Rajesh\", \"Rajeev\", \"Suresh\", \"Mahesh\", \"Priya\", \"Priyanka\",\n",
    "    \"Arun\", \"Arjun\", \"Varun\", \"Anjali\", \"Anjalika\", \"Deepak\",\n",
    "    \"Deepa\", \"Sanjay\", \"Sanjeev\", \"Amit\", \"Amita\", \"Vikram\",\n",
    "    \"Vikas\", \"Rahul\"\n",
    "]\n",
    "\n",
    "def simhash(text, hash_bits=32):\n",
    "    \"\"\"SimHash returning binary string representation\"\"\"\n",
    "    text = text.lower()\n",
    "    features = [text[i:i+2] for i in range(len(text) - 1)]\n",
    "    v = [0] * hash_bits\n",
    "    \n",
    "    for feature in features:\n",
    "        h = int(hashlib.md5(feature.encode()).hexdigest(), 16)\n",
    "        for i in range(hash_bits):\n",
    "            if h & (1 << i):\n",
    "                v[i] += 1\n",
    "            else:\n",
    "                v[i] -= 1\n",
    "    \n",
    "    fingerprint = 0\n",
    "    for i in range(hash_bits):\n",
    "        if v[i] > 0:\n",
    "            fingerprint |= (1 << i)\n",
    "    \n",
    "    # Return as binary string\n",
    "    return format(fingerprint, f'0{hash_bits}b')\n",
    "\n",
    "# Show different output formats for the same hash\n",
    "print(\"32-BIT HASH OUTPUT FORMATS\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'Name':<12} {'Binary (32-bit)':<35} {'Hex':<12} {'Integer':<12}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for name in indian_names[:10]:  # Show first 10 for clarity\n",
    "    binary = simhash(name, 32)\n",
    "    hex_val = format(int(binary, 2), '08x')\n",
    "    int_val = int(binary, 2)\n",
    "    \n",
    "    print(f\"{name:<12} {binary:<35} {hex_val:<12} {int_val:<12}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "\n",
    "\n",
    "# Compare similar names\n",
    "name1, name2 = \"Rajesh\", \"Rajeev\"\n",
    "h1_bin = simhash(name1, 32)\n",
    "h2_bin = simhash(name2, 32)\n",
    "h1_hex = format(int(h1_bin, 2), '08x')\n",
    "h2_hex = format(int(h2_bin, 2), '08x')\n",
    "\n",
    "print(f\"{name1:<10} (binary): {h1_bin}\")\n",
    "print(f\"{name2:<10} (binary): {h2_bin}\")\n",
    "print()\n",
    "print(f\"{name1:<10} (hex):    {h1_hex}\")\n",
    "print(f\"{name2:<10} (hex):    {h2_hex}\")\n",
    "print()\n",
    "\n",
    "# Calculate Hamming distance\n",
    "hamming = sum(b1 != b2 for b1, b2 in zip(h1_bin, h2_bin))\n",
    "print(f\"Hamming Distance: {hamming} bits out of 32\")\n",
    "print(f\"Similarity: {(32 - hamming) / 32 * 100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"\\nRECOMMENDATION:\")\n",
    "print(\"- Use BINARY STRINGS for analysis, visualization, and understanding\")\n",
    "print(\"- Use HEX for compact storage and display\")\n",
    "print(\"- Use INTEGER for mathematical operations and indexing\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ac936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
