{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e182839",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_semantic_hashing = [\n",
    "  \"SimHash\",\n",
    "  \"MinHash\",\n",
    "  \"Random Projection LSH\",\n",
    "  \"Random Hyperplane Hashing\",\n",
    "  \"Feature Hashing\",\n",
    "  \"Spectral Hashing\",\n",
    "  \"Iterative Quantization (ITQ)\",\n",
    "  \"Character Hash\",\n",
    "  \"N-gram Hash\",\n",
    "  \"Phonetic Hash\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77ac936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def simhash(text, hash_bits=32):\n",
    "    text = text.lower()\n",
    "    features = [text[i:i+2] for i in range(len(text) - 1)]\n",
    "    v = [0] * hash_bits\n",
    "    \n",
    "    for feature in features:\n",
    "        h = int(hashlib.md5(feature.encode()).hexdigest(), 16)\n",
    "        for i in range(hash_bits):\n",
    "            if h & (1 << i):\n",
    "                v[i] += 1\n",
    "            else:\n",
    "                v[i] -= 1\n",
    "    \n",
    "    fingerprint = 0\n",
    "    for i in range(hash_bits):\n",
    "        if v[i] > 0:\n",
    "            fingerprint |= (1 << i)\n",
    "    \n",
    "    return format(fingerprint, '08x')\n",
    "\n",
    "def minhash(text, num_hashes=32):\n",
    "    text = text.lower()\n",
    "    shingles = set(text[i:i+2] for i in range(len(text) - 1))\n",
    "    \n",
    "    hash_val = 0\n",
    "    for i in range(num_hashes):\n",
    "        min_hash = float('inf')\n",
    "        for shingle in shingles:\n",
    "            h = int(hashlib.md5(f\"{shingle}{i}\".encode()).hexdigest()[:8], 16)\n",
    "            min_hash = min(min_hash, h)\n",
    "        if (min_hash % 2) == 0:\n",
    "            hash_val |= (1 << i)\n",
    "    \n",
    "    return format(hash_val, '08x')\n",
    "\n",
    "def random_projection_lsh(text, num_projections=32, seed=42):\n",
    "    text = text.lower()\n",
    "    feature_vec = [text.count(chr(ord('a') + i)) for i in range(26)]\n",
    "    \n",
    "    hash_val = 0\n",
    "    for i in range(num_projections):\n",
    "        projection = sum(\n",
    "            feature_vec[j] * ((hash((seed, i, j)) % 3) - 1)\n",
    "            for j in range(len(feature_vec))\n",
    "        )\n",
    "        if projection > 0:\n",
    "            hash_val |= (1 << i)\n",
    "    \n",
    "    return format(hash_val, '08x')\n",
    "\n",
    "def random_hyperplane_hash(text, num_planes=32, seed=123):\n",
    "    text = text.lower()\n",
    "    feature_vec = [text.count(chr(ord('a') + i)) for i in range(26)]\n",
    "    \n",
    "    hash_val = 0\n",
    "    for i in range(num_planes):\n",
    "        dot_product = sum(\n",
    "            feature_vec[j] * ((hash((seed, i, j)) % 5) - 2)\n",
    "            for j in range(len(feature_vec))\n",
    "        )\n",
    "        if dot_product > 0:\n",
    "            hash_val |= (1 << i)\n",
    "    \n",
    "    return format(hash_val, '08x')\n",
    "\n",
    "def feature_hash(text, hash_bits=32):\n",
    "    text = text.lower()\n",
    "    features = [\n",
    "        len(text),\n",
    "        sum(text.count(v) for v in 'aeiou'),\n",
    "        sum(text.count(c) for c in 'bcdfghjklmnpqrstvwxyz'),\n",
    "        ord(text[0]) if text else 0,\n",
    "        ord(text[-1]) if text else 0,\n",
    "        len(set(text)),\n",
    "    ]\n",
    "    \n",
    "    hash_input = ''.join(str(v) for v in features)\n",
    "    h = int(hashlib.md5(hash_input.encode()).hexdigest(), 16)\n",
    "    \n",
    "    return format(h % (2**hash_bits), '08x')\n",
    "\n",
    "def spectral_hash(text, hash_bits=32):\n",
    "    text = text.lower()\n",
    "    freq = [0] * 26\n",
    "    for char in text:\n",
    "        if 'a' <= char <= 'z':\n",
    "            freq[ord(char) - ord('a')] += 1\n",
    "    \n",
    "    hash_val = 0\n",
    "    for i in range(hash_bits):\n",
    "        idx1 = (i * 7) % 26\n",
    "        idx2 = (i * 13) % 26\n",
    "        if freq[idx1] - freq[idx2] > 0:\n",
    "            hash_val |= (1 << i)\n",
    "    \n",
    "    return format(hash_val, '08x')\n",
    "\n",
    "def itq_hash(text, hash_bits=32):\n",
    "    text = text.lower()\n",
    "    features = [text.count(chr(ord('a') + i)) for i in range(26)]\n",
    "    \n",
    "    hash_val = 0\n",
    "    for i in range(hash_bits):\n",
    "        idx1 = (i * 3) % 26\n",
    "        idx2 = (i * 5) % 26\n",
    "        rotated_val = features[idx1] - features[idx2]\n",
    "        if rotated_val > 0:\n",
    "            hash_val |= (1 << i)\n",
    "    \n",
    "    return format(hash_val, '08x')\n",
    "\n",
    "def character_hash(text, hash_bits=32):\n",
    "    text = text.lower()\n",
    "    hash_val = 0\n",
    "    \n",
    "    for i in range(min(len(text), hash_bits)):\n",
    "        char_val = ord(text[i]) if i < len(text) else 0\n",
    "        if (char_val * (i + 1)) % 2 == 0:\n",
    "            hash_val |= (1 << i)\n",
    "    \n",
    "    return format(hash_val, '08x')\n",
    "\n",
    "def ngram_hash(text, hash_bits=32):\n",
    "    text = text.lower()\n",
    "    patterns = ['a', 'e', 'i', 'o', 'u', 'ra', 'an', 'ar', 'sh', 'ee', \n",
    "                'ja', 'vi', 'sa', 'pr', 'de', 'am']\n",
    "    \n",
    "    hash_val = 0\n",
    "    for i, pattern in enumerate(patterns[:hash_bits]):\n",
    "        if pattern in text:\n",
    "            hash_val |= (1 << i)\n",
    "    \n",
    "    return format(hash_val, '08x')\n",
    "\n",
    "def phonetic_hash(text, hash_bits=32):\n",
    "    text = text.lower()\n",
    "    \n",
    "    features = []\n",
    "    features.append(1 if any(v in text for v in 'aeiou') else 0)\n",
    "    features.append(1 if 'sh' in text or 'ch' in text else 0)\n",
    "    features.append(1 if 'th' in text or 'ph' in text else 0)\n",
    "    features.append(1 if text.startswith(tuple('aeiou')) else 0)\n",
    "    features.append(1 if text.endswith(tuple('aeiou')) else 0)\n",
    "    \n",
    "    for cons in ['r', 'j', 's', 'v', 'k', 'm', 'n', 'd', 'p']:\n",
    "        features.append(1 if cons in text else 0)\n",
    "    \n",
    "    hash_val = 0\n",
    "    for i, feature in enumerate(features[:hash_bits]):\n",
    "        if feature:\n",
    "            hash_val |= (1 << i)\n",
    "    \n",
    "    return format(hash_val, '08x')\n",
    "\n",
    "def hamming_distance(h1, h2):\n",
    "    x = int(h1, 16) ^ int(h2, 16)\n",
    "    return bin(x).count('1')\n",
    "\n",
    "def similarity_score(hamming_dist, total_bits=32):\n",
    "    return ((total_bits - hamming_dist) / total_bits) * 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee468a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a15ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_names = [\n",
    "    \"Suresh\", \"Mahesh\",\n",
    "    \"Arun\", \"Arjun\", \"Varun\", \"Deepak\",\n",
    "    \"Deepa\", \"Sanjay\", \"Sanjeev\", \"Vikram\",\n",
    "    \"Vikas\", \"Sujesh\", \"Sujeesh\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c02d9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Name    | SimHash   | MinHash   | RandProj   | RandHP   | Feature   | Spectral   | ITQ      | CharHash   |   N-gram | Phonetic   |\n",
      "+=========+===========+===========+============+==========+===========+============+==========+============+==========+============+\n",
      "| Suresh  | d8e4fcb6  | 3f9add43  | 00aaa8c0   | 29542b59 | ed6cc774  | 08204502   | 01800c40 | 0000002e   | 00000112 | 000000a3   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Mahesh  | 57a5cea0  | 15785d47  | 20abfdc8   | 695cab1d | dec57bc6  | 08000002   | 40000c10 | 0000002e   | 00000103 | 00000483   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Arun    | b2416e82  | 13153bdb  | c8000aa2   | 295c2b4b | fbfb092e  | 00000000   | 01800000 | 0000000a   | 00000091 | 00000829   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Arjun   | c0012e04  | 82df3fd3  | c8000ab2   | 295c6b5a | 242b08c5  | 00000000   | 21800008 | 0000001e   | 00000091 | 00000869   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Varun   | b0416802  | 031d3bdf  | c8002aa2   | 295c2b4b | 0750e50b  | 00000000   | 01800080 | 0000001f   | 00000091 | 00000921   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Deepak  | 1522be5e  | 4caa7658  | aa2be66a   | 2954ab19 | 16f69282  | 000a0100   | 88001422 | 0000002b   | 00004203 | 00003201   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Deepa   | 11020c5c  | 4caa7678  | 222be448   | 2d54ab19 | 075369af  | 000a0100   | 88000422 | 0000000b   | 00004203 | 00003011   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Sanjay  | c59e2eac  | f9a09e1e  | 88008ee2   | 2b546b78 | 7b47d608  | 00000000   | 20000148 | 0000002e   | 00001441 | 000008c1   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Sanjeev | 4d8a080c  | ada4bfee  | 880aec82   | 2d54eb1b | f8982be7  | 00000100   | 20000408 | 0000006e   | 00001243 | 000009c1   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Vikram  | 2b386d36  | c99565d3  | 880acea2   | 2954ab1b | a1274628  | 20200008   | 40900090 | 0000002b   | 00008825 | 00000721   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Vikas   | 3908312a  | d09a646e  | 882aec82   | 2b56eb1b | 5da7f5f8  | 20000008   | 001000c0 | 0000000b   | 00000805 | 00000381   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Sujesh  | cdc5cca2  | 4bb91d66  | 20aaa8c8   | 2b57a358 | ed6cc774  | 88004522   | 21000c48 | 0000002e   | 00000112 | 000000c3   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n",
      "| Sujeesh | 4dc0c882  | 4da81d6e  | 202aa8c8   | 2956ab59 | 9d68b8aa  | 88004522   | 21000c08 | 0000006e   | 00000312 | 000000c3   |\n",
      "+---------+-----------+-----------+------------+----------+-----------+------------+----------+------------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "table_data = []\n",
    "headers = [\"Name\", \"SimHash\", \"MinHash\", \"RandProj\", \"RandHP\", \"Feature\", \n",
    "           \"Spectral\", \"ITQ\", \"CharHash\", \"N-gram\", \"Phonetic\"]\n",
    "for name in indian_names:\n",
    "    row = [\n",
    "        name,\n",
    "        simhash(name),\n",
    "        minhash(name),\n",
    "        random_projection_lsh(name),\n",
    "        random_hyperplane_hash(name),\n",
    "        feature_hash(name),\n",
    "        spectral_hash(name),\n",
    "        itq_hash(name),\n",
    "        character_hash(name),\n",
    "        ngram_hash(name),\n",
    "        phonetic_hash(name)\n",
    "    ]\n",
    "    table_data.append(row)\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc05e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n",
      "| Name Pair       | SimHash   | MinHash   | RandProj   | RandHP   | Feature   | Spectral   | ITQ    | CharHash   | N-gram   | Phonetic   |\n",
      "+=================+===========+===========+============+==========+===========+============+========+============+==========+============+\n",
      "| Rajesh-Rajeev   | 84.4%     | 56.2%     | 84.4%      | 84.4%    | 59.4%     | 84.4%      | 96.9%  | 100.0%     | 93.8%    | 90.6%      |\n",
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n",
      "| Arun-Arjun      | 71.9%     | 71.9%     | 96.9%      | 90.6%    | 46.9%     | 100.0%     | 93.8%  | 93.8%      | 100.0%   | 96.9%      |\n",
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n",
      "| Varun-Arun      | 87.5%     | 90.6%     | 96.9%      | 100.0%   | 40.6%     | 100.0%     | 96.9%  | 90.6%      | 100.0%   | 93.8%      |\n",
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n",
      "| Amit-Amita      | 81.2%     | 81.2%     | 96.9%      | 93.8%    | 50.0%     | 100.0%     | 100.0% | 100.0%     | 100.0%   | 96.9%      |\n",
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n",
      "| Deepak-Deepa    | 78.1%     | 96.9%     | 84.4%      | 96.9%    | 46.9%     | 100.0%     | 96.9%  | 96.9%      | 100.0%   | 93.8%      |\n",
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n",
      "| Anjali-Anjalika | 75.0%     | 84.4%     | 93.8%      | 96.9%    | 46.9%     | 100.0%     | 100.0% | 96.9%      | 100.0%   | 96.9%      |\n",
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n",
      "| Sanjay-Sanjeev  | 71.9%     | 68.8%     | 78.1%      | 78.1%    | 25.0%     | 96.9%      | 90.6%  | 96.9%      | 90.6%    | 96.9%      |\n",
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n",
      "| Vikas-Vikram    | 65.6%     | 56.2%     | 87.5%      | 90.6%    | 53.1%     | 96.9%      | 87.5%  | 96.9%      | 93.8%    | 90.6%      |\n",
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n",
      "| Sujesh-Sujeesh  | 84.4%     | 84.4%     | 96.9%      | 87.5%    | 46.9%     | 100.0%     | 96.9%  | 96.9%      | 96.9%    | 100.0%     |\n",
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n",
      "| AVERAGE         | 77.8%     | 76.7%     | 90.6%      | 91.0%    | 46.2%     | 97.6%      | 95.5%  | 96.5%      | 97.2%    | 95.1%      |\n",
      "+-----------------+-----------+-----------+------------+----------+-----------+------------+--------+------------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Similar pairs\n",
    "similar_pairs = [\n",
    "    (\"Rajesh\", \"Rajeev\"),\n",
    "    (\"Arun\", \"Arjun\"),\n",
    "    (\"Varun\", \"Arun\"),\n",
    "    (\"Amit\", \"Amita\"),\n",
    "    (\"Deepak\", \"Deepa\"),\n",
    "    (\"Anjali\", \"Anjalika\"),\n",
    "    (\"Sanjay\", \"Sanjeev\"),\n",
    "    (\"Vikas\", \"Vikram\"),\n",
    "    (\"Sujesh\", \"Sujeesh\")\n",
    "]\n",
    "\n",
    "algorithms = [\n",
    "    (\"SimHash\", simhash),\n",
    "    (\"MinHash\", minhash),\n",
    "    (\"RandProj\", random_projection_lsh),\n",
    "    (\"RandHP\", random_hyperplane_hash),\n",
    "    (\"Feature\", feature_hash),\n",
    "    (\"Spectral\", spectral_hash),\n",
    "    (\"ITQ\", itq_hash),\n",
    "    (\"CharHash\", character_hash),\n",
    "    (\"N-gram\", ngram_hash),\n",
    "    (\"Phonetic\", phonetic_hash)\n",
    "]\n",
    "\n",
    "# Prepare data for tabulate\n",
    "table_data = []\n",
    "headers = [\"Name Pair\", \"SimHash\", \"MinHash\", \"RandProj\", \"RandHP\", \"Feature\", \n",
    "           \"Spectral\", \"ITQ\", \"CharHash\", \"N-gram\", \"Phonetic\"]\n",
    "\n",
    "# Track scores for averaging\n",
    "algo_scores = {algo_name: [] for algo_name, _ in algorithms}\n",
    "\n",
    "for name1, name2 in similar_pairs:\n",
    "    pair_name = f\"{name1}-{name2}\"\n",
    "    row = [pair_name]\n",
    "    \n",
    "    for algo_name, algo_func in algorithms:\n",
    "        h1 = algo_func(name1)\n",
    "        h2 = algo_func(name2)\n",
    "        hamming = hamming_distance(h1, h2)\n",
    "        similarity = similarity_score(hamming)\n",
    "        \n",
    "        algo_scores[algo_name].append(similarity)\n",
    "        row.append(f\"{similarity:.1f}%\")\n",
    "    \n",
    "    table_data.append(row)\n",
    "\n",
    "# Add average row\n",
    "avg_row = [\"AVERAGE\"]\n",
    "for algo_name, _ in algorithms:\n",
    "    avg_score = sum(algo_scores[algo_name]) / len(algo_scores[algo_name])\n",
    "    avg_row.append(f\"{avg_score:.1f}%\")\n",
    "\n",
    "table_data.append(avg_row)\n",
    "\n",
    "# Display using tabulate\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceaada1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
